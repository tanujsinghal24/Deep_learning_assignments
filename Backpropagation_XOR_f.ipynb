{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tanuj Singhal - Backpropagation_XOR_f.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["9-0oU2fCdhRN"]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ly0FEPLRRA3R"},"source":["## Implementing Back-propagation Algorithm with XOR data\n","\n","### XOR data: <br>\n","**$ x_0 \\ x_1 \\ y$** <br>\n","$0 \\ \\ \\  0 \\ \\ \\  0$ <br>\n","$0 \\ \\ \\  1 \\ \\ \\  1$ <br>\n","$1 \\ \\ \\  0 \\ \\ \\  1$<br>\n","$1 \\ \\ \\  1 \\ \\ \\  0$<br>\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Iewd7ysumt1L","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xYnKrpHRC88X"},"source":["##Activation function\n","\n","Sigmoid function $$\\frac{1}{1+ e^{-x}} $$"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"RR5ReWLb0rQ8","nbgrader":{"checksum":"f4effe0bb558b3f87da12a7a5133ee75","grade":false,"grade_id":"cell-d84ad9dbcb889c3f","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["#Define our activation function\n","\n","def sigmoid (x):\n","    '''\n","    Input:\n","        x: numpy array of any shape\n","    Output:\n","        y: numpy array of same shape as x\n","    '''\n","    # YOUR CODE HERE\n","    return 1/(1+np.exp(-x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"4q5l-n3LkamT","nbgrader":{"checksum":"8556b6d6d8fb50561b6a4b23e4f428e2","grade":true,"grade_id":"cell-80b53c7b5034f924","locked":true,"points":1,"schema_version":1,"solution":false},"outputId":"3268be01-87b5-410a-c548-3acc90e5ac8b","executionInfo":{"status":"ok","timestamp":1560043428664,"user_tz":-330,"elapsed":1434,"user":{"displayName":"Tanuj Singhal","photoUrl":"","userId":"15993466899445923096"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["'''Testing'''\n","assert sigmoid(0)==0.5\n","assert np.isclose(sigmoid(-2), 0.119202922, atol=0.0001)\n","print('Test passed', '\\U0001F44D')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Test passed üëç\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"hAS1d1_Wkama","nbgrader":{"checksum":"b5988d9e371e77c56c63d315f5c63d3e","grade":false,"grade_id":"cell-9ebb909521c85d2b","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["# Define the activation function derivative\n","\n","def sigmoid_derivative(x):\n","    '''\n","    Input:\n","        x: numpy array of any shape\n","    Output:\n","        y: numpy array of same shape as x\n","        y = derivative of sigmoid\n","    '''\n","    # YOUR CODE HERE\n","#     print(sigmoid(0)*(1-sigmoid(0)))\n","    return x*(1-x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"D27idxL-kami","nbgrader":{"checksum":"d980605ecd57b9e69ac9a07ec6cfbc06","grade":true,"grade_id":"cell-8668ae928d66bf7c","locked":true,"points":1,"schema_version":1,"solution":false},"outputId":"f4c460d5-2713-481f-f07a-89a4c6e82280","executionInfo":{"status":"ok","timestamp":1560043428669,"user_tz":-330,"elapsed":957,"user":{"displayName":"Tanuj Singhal","photoUrl":"","userId":"15993466899445923096"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["'''Testing code for sigmoid_derivative'''\n","assert sigmoid_derivative(1) == 0\n","assert sigmoid_derivative(0) == 0\n","print('Test passed', '\\U0001F44D')\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Test passed üëç\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7QEVx1qpYo3m"},"source":["## Defining the model"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"QiXPUCkdP5ky","nbgrader":{"checksum":"4646c91497019ffdff3cd615c01b92a9","grade":false,"grade_id":"cell-4a7dcd60006d48dc","locked":false,"schema_version":1,"solution":true},"colab":{}},"source":["#Define the NeuralNetwork class\n","\n","class NeuralNetwork:\n","    def __init__(self, net_arch):\n","        '''   \n","        Input:\n","            net_arch: list of 3 integers\n","        Action:\n","            Creates instance variables:\n","                self.input: np array of shape (ni,1)\n","                self.layer1: nprarray of shape (nh,1)\n","                self.output: np array of shape (no,1)\n","                self.weights1: np array of shape (nh, ni), initialized randomly between (-1,1)\n","                self.weights2: np array of shape (no, nh), initialized randomly between (-1,1)\n","                \n","            NOTE: We do not use bias explicitly here. Input x can have the first element 1 to have a bias term.\n","        '''\n","        ni = net_arch[0]  ## Number of neurons in input layer    \n","        nh = net_arch[1]  ## Number of neurons in hidden layer\n","        no = net_arch[2]  ## Number of neurons in output layer\n","        \n","        self.ni = ni\n","        self.nh = nh\n","        self.no = no\n","        \n","        # YOUR CODE HERE\n","        self.input=np.random.rand(self.ni,1)   # np array of shape (ni,1)\n","        self.layer1= np.random.rand(self.nh,1)  # nprarray of shape (nh,1)\n","        self.output=np.random.rand(self.no,1) # np array of shape (no,1)\n","        self.weights1= 2*np.random.rand(self.nh,ni)-1 # np array of shape (nh, ni), initialized randomly between (-1,1)\n","        self.weights2= 2*np.random.rand(self.no,nh)-1 # np array of shape (no, nh), initialized randomly between (-1,1)\n","    \n","    def feedforward(self,x):\n","        '''\n","        Input:\n","            x: numpy array of shape (ni,1)\n","        Action:\n","            \n","        Return:\n","            output: numpy array of shape (no,1),\n","        '''\n","        # YOUR CODE HERE\n","#         hi_1=[]\n","#         for i in range(x.shape[0]):\n","#         print('x=',x)\n","#         print('feed x.shape=',x.shape)\n","#         print('self.weights1=',self.weights1.shape)\n","#         print('x.shape=',x.shape)\n","\n","#         hi_1= self.weights1.dot(x)\n","#          print('hi_1.shape=',hi_1.shape)\n","        \n","\n","#  hi_1= self.weights1.dot(x)\n","#         print('hi_1=',hi_1)\n","        x=x.reshape(-1,1)\n","        self.layer1 = sigmoid(np.dot(self.weights1, x)).reshape(-1, 1)\n","        y = sigmoid(np.dot(self.weights2, self.layer1)).reshape(-1,1)\n","#         print('y=',y)\n","        \n","#         print('w2=.shape=',self.weights2.shape,'    w2=',self.weights2)\n","#         print('w2=.shape=',self.weights1.shape,'    w2=',self.weights1)\n","        return y\n","             \n","\n","    def backprop(self,x,y,eta):\n","        '''\n","        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n","        Input:\n","            x: numpy array of shape (ni,1)\n","            y: numpy array of shape (no,1)\n","            eta: learning rate\n","        Action:\n","        # Finding the derivatives\n","            del_weights2: np array of shape (no,nh) that stores the derivative of the loss function with respect to weights2\n","            del_weights1: np array of shape (nh,ni) that stores the derivative of the loss function with respect to weights1\n","            \n","        # Update the weights with the derivative of the loss function\n","            weights1 += eta*del_weights1\n","            weights2 += eta*del_weights2\n","        '''\n","   \n","        # YOUR CODE HERE\n","#         print(' back start')\n","#         print('back x.shape=',x.shape)\n","#         print('x=',x)\n","#         print('y=',y)\n","#         del_weights2 = ((y - self.output) * sigmoid_derivative(self.output)).dot(self.layer1.reshape(self.nh, 1).T)\n","#         del_weights1 = ((y - self.output) * sigmoid_derivative(self.output)*self.weights2.T * sigmoid_derivative(self.layer1)).dot(x.T)\n","#         self.weights1 += eta*del_weights1\n","#         self.weights2 += eta*del_weights2\n","        \n","#         print('del_weights1.shape=',del_weights1.shape)\n","#         print('del_weights2.shape=',del_weights2.shape)\n","        self.del_weights2 = np.dot(((y-self.output) * sigmoid_derivative(y)),self.layer1.reshape(-1, 1).T)\n","        self.del_weights1 = np.dot(((y-self.output) * sigmoid_derivative(y)*self.weights2.T * sigmoid_derivative(self.layer1)), x.reshape(1,3))\n","      \n","    \n","#         for s in range(X.shape[0]):\n","#           print('s=',s)\n","#           print('Y.shape=',Y.shape)\n","#           print('self.output.shape=',self.output.shape)\n","\n","#           del_weights2 = np.dot(((Y[s] - self.output) * sigmoid_derivative(self.output)),self.layer1.reshape(-1, 1).T)\n","#           del_weights1 = np.dot(((Y[s]-self.output) * sigmoid_derivative(self.output)*self.weights2.T * sigmoid_derivative(self.layer1)), X[s].reshape(1,-1))  \n","          \n","#           self.weights1=  del_weights1+ eta*del_weights1\n","#           self.weights2 =  del_weights2 + eta*del_weights2\n","          \n","# #           print('self.del_weights1=',del_weights1)\n","#           print('self.del_weights1.shape=',del_weights1.shape)\n","# #           print('self.del_weights2=',del_weights2)\n","#           print('self.del_weights2.shape=',del_weights2.shape)\n","#           print('self.weights1.shape=',self.weights1.shape)\n","#           print('self.weights2.shape=',self.weights2.shape)\n","\n","    def fit(self, X, Y, eta, epochs):\n","        '''\n","        input:\n","        X: training input data of shape (4,2)\n","        Y: training output of shape (4,1)\n","        eta: learning rate\n","        epochs: number of epochs\n","        Action:\n","        # Modify the input by adding ones of shape(4,1) \n","        # Set up the feed-forward propagation for the modified input   \n","        # Set up the back-propagation of the error to adjust the weights\n","        '''\n","        # YOUR CODE HERE\n","        add1col= lambda x: np.concatenate((x,np.ones((x.shape[0],1))),axis=1)\n","#         self.input=add1col(X)\n","         \n","        X=add1col(X)\n","        print('X afer add1col=',X)\n","        for epochs in range(5000):\n","          for s in range(X.shape[0]):\n","            self.output=self.feedforward(X[s])\n","            self.backprop(X[s],Y[s],eta)\n","            self.weights1 = self.weights1 + eta*self.del_weights1\n","            self.weights2 = self.weights2 + eta*self.del_weights2\n","    def predict(self,x,y):\n","        '''\n","        # Predict function is used to check the prediction result of the neural network\n","        Input:\n","        x: single input data of shape (1,3)\n","        y: single output data of shape (1,1)\n","        Action\n","        pred_out: predict the output based on the model using feedforward\n","        \n","        Output\n","        error: y - pred_out\n","        \n","        \n","        '''\n","        # YOUR CODE HERE\n","#         add1col= lambda x: np.concatenate((x,np.ones((x.shape[0],1))),axis=1)\n","# #         self.input=add1col(X)\n","         \n","#         x=add1col(x)\n","        print(x.shape)\n","        x=x.reshape(-1,3)\n","        error = 0\n","#         self.fit(x,y,1,100)\n","        for s in range(x.shape[0]):\n","          self.output=self.feedforward(x[s].reshape(-1,3))\n","    \n","#           print('x:',x[s,:-1],' y:',self.output)\n","          error += (y - self.output).dot(y - self.output)\n","\n","#         print('error:',error/4)     \n","        return(error)\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"6gp5eg0skamy","nbgrader":{"checksum":"01c984c866bc53a22934b3a8a85bb6ae","grade":true,"grade_id":"cell-640694d6a41609e8","locked":true,"points":2,"schema_version":1,"solution":false},"outputId":"7b2de42b-ae18-4dc6-991d-e45995780ae7","executionInfo":{"status":"ok","timestamp":1560046034711,"user_tz":-330,"elapsed":1215,"user":{"displayName":"Tanuj Singhal","photoUrl":"","userId":"15993466899445923096"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["'''Testing code for __init__'''\n","\n","net_arch = [3,4,1]\n","nn1 = NeuralNetwork(net_arch)\n","assert nn1.input.shape==(3,1)\n","assert nn1.layer1.shape == (4,1)\n","assert nn1.output.shape == (1,1)\n","assert np.all(nn1.weights1 < 1)\n","print('Test passed', '\\U0001F44D')\n"],"execution_count":147,"outputs":[{"output_type":"stream","text":["Test passed üëç\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"hP6uPl-2kanA","nbgrader":{"checksum":"2bcf8c9fbcf3690b31a8c6a9cde70928","grade":true,"grade_id":"cell-f0a271c06ea8c25b","locked":true,"points":2,"schema_version":1,"solution":false},"outputId":"218b8598-7918-46f0-a36a-8f8a80b6c0c2","executionInfo":{"status":"ok","timestamp":1560046034713,"user_tz":-330,"elapsed":1027,"user":{"displayName":"Tanuj Singhal","photoUrl":"","userId":"15993466899445923096"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["'''Testing code for feedforward'''\n","\n","def feedforward_original(nn1,x):\n","    assert x.shape == (nn1.ni, 1)\n","    layer1 = sigmoid(np.dot(nn1.weights1, x))\n","    output = sigmoid(np.dot(nn1.weights2, layer1))\n","    return output\n","x = np.array([0,1,1]).reshape(-1, 1)\n","assert nn1.feedforward(x) == feedforward_original(nn1, x)\n","print('Test passed', '\\U0001F44D')"],"execution_count":148,"outputs":[{"output_type":"stream","text":["Test passed üëç\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"XBXXqFAKYxnv","nbgrader":{"checksum":"3737666b17aaad1d4a58603c7b67ce81","grade":true,"grade_id":"cell-a4a2893378d844f3","locked":true,"points":4,"schema_version":1,"solution":false},"outputId":"fce0e25e-0cfc-4189-8efb-42cf181076cb","executionInfo":{"status":"ok","timestamp":1560046034714,"user_tz":-330,"elapsed":735,"user":{"displayName":"Tanuj Singhal","photoUrl":"","userId":"15993466899445923096"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["'''Testing code for backprop'''\n","def backprop_original(nn1,x,y,eta):\n","    weights1 = nn1.weights1\n","    weights2 = nn1.weights2\n","    del_weights2 = np.dot(((y - nn1.output) * sigmoid_derivative(nn1.output)),nn1.layer1.reshape(-1, 1).T)\n","    del_weights1 = np.dot(((y - nn1.output) * sigmoid_derivative(nn1.output)*nn1.weights2.T * sigmoid_derivative(nn1.layer1)), x.T)\n","\n","    # update the weights with the derivative (slope) of the loss function\n","    weights1 += eta*del_weights1\n","    weights2 += eta*del_weights2\n","    return(weights1, weights2)\n","\n","x = np.array([0,1,1]).reshape(-1, 1)\n","y = np.array([[0],])\n","eta = 1\n","nn1.backprop(x, y, eta)\n","w1, w2 = backprop_original(nn1, x, y, eta) \n","assert np.all(np.isclose(w1, nn1.weights1))\n","assert np.all(np.isclose(w2, nn1.weights2))\n","print('Test passed', '\\U0001F44D')"],"execution_count":149,"outputs":[{"output_type":"stream","text":["Test passed üëç\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tUs7Wwu7ZjBX"},"source":["## Fitting the data (Training)"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"kbRcD6R6RBpw","nbgrader":{"checksum":"dbbf11073bfdce0010e10e0eaca6500c","grade":false,"grade_id":"cell-e59bb4a5a7ddab07","locked":false,"schema_version":1,"solution":true},"outputId":"93629933-b2cf-4b3a-b9eb-7984e319b2fc","executionInfo":{"status":"ok","timestamp":1560046035123,"user_tz":-330,"elapsed":847,"user":{"displayName":"Tanuj Singhal","photoUrl":"","userId":"15993466899445923096"}},"colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["## CHECK THE PERFORMANCE\n","'''\n","Input:\n","# Set the input data\n","X = ([[0.1, 0.1], [0.1, 0.9],\n","                [0.9, 0.1], [0.9, 0.9]])\n","# Set the labels, the correct results for the xor operation\n","Y = ([[0.1], [0.9], \n","                 [0.9], [0.1]])\n","Action:\n","# Initialize the NeuralNetwork with\n","# 3 input neurons\n","# 4 hidden neurons\n","# 1 output neuron\n","\n","# Fit the datas\n","'''\n","# YOUR CODE HERE\n"],"execution_count":150,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nInput:\\n# Set the input data\\nX = ([[0.1, 0.1], [0.1, 0.9],\\n                [0.9, 0.1], [0.9, 0.9]])\\n# Set the labels, the correct results for the xor operation\\nY = ([[0.1], [0.9], \\n                 [0.9], [0.1]])\\nAction:\\n# Initialize the NeuralNetwork with\\n# 3 input neurons\\n# 4 hidden neurons\\n# 1 output neuron\\n\\n# Fit the datas\\n'"]},"metadata":{"tags":[]},"execution_count":150}]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"-aYoNXSF2f9F","nbgrader":{"checksum":"b1a894b26291672207fabd649f07486d","grade":true,"grade_id":"cell-7391ad1a93e30118","locked":true,"points":3,"schema_version":1,"solution":false},"outputId":"5f9fd5de-c7d0-4f07-965d-83f86b78f627","executionInfo":{"status":"ok","timestamp":1560046035788,"user_tz":-330,"elapsed":1334,"user":{"displayName":"Tanuj Singhal","photoUrl":"","userId":"15993466899445923096"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["'''Testing for fit'''\n","X = np.array([[0.1, 0.1], [0.1, 0.9],\n","                [0.9, 0.1], [0.9, 0.9]])\n","# Set the labels, the correct results for the xor operation\n","Y = np.array([[0.1], [0.9], \n","                 [0.9], [0.1]])\n","nn1.fit(X,Y,1,100)\n","x = np.array([1,1,1]).reshape(-1, 1)\n","y = np.array([[0],])\n","print(nn1.feedforward(x),y)\n","assert np.all(np.isclose(nn1.feedforward(x),y,atol=0.1))\n","print('Test passed', '\\U0001F44D')"],"execution_count":151,"outputs":[{"output_type":"stream","text":["X afer add1col= [[0.1 0.1 1. ]\n"," [0.1 0.9 1. ]\n"," [0.9 0.1 1. ]\n"," [0.9 0.9 1. ]]\n","[[0.07222689]] [[0]]\n","Test passed üëç\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SLXYzUB4fs8o"},"source":["## Plotting "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"H2XKM2sufuwL","colab":{}},"source":["def plotting(X, Y):\n","  x_plot = X.T\n","  color = []\n","  for i in Y:\n","    if i[0] == 0:\n","      color.append('g')\n","    else:\n","      color.append('r')\n","  color = np.array(color)\n","  print(x_plot)\n","  plt.figure()\n","  plt.xlabel('x1')\n","  plt.ylabel('x2')\n","  plt.scatter(x_plot[0],x_plot[1],color=color)\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PWvKv62qsiLP","outputId":"78b62760-276b-4ba2-fb8e-09d1dc81f144","executionInfo":{"status":"ok","timestamp":1560046037086,"user_tz":-330,"elapsed":1334,"user":{"displayName":"Tanuj Singhal","photoUrl":"","userId":"15993466899445923096"}},"colab":{"base_uri":"https://localhost:8080/","height":317}},"source":["plotting(X, Y)"],"execution_count":153,"outputs":[{"output_type":"stream","text":["[[0.1 0.1 0.9 0.9]\n"," [0.1 0.9 0.1 0.9]]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCQV/w8q5xjflva8QQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K1PPPHD9aDM-"},"source":["## Could you test it now?\n","\n","Find the error between the predicted output and the desired output."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XGQZuMbihk-1","colab":{}},"source":["def testing(X, Y):\n","  ones = 0.9*np.ones((X.shape[0],1))\n","  x_test = np.concatenate([ones, X], axis=1)\n","  y_test = Y\n","\n","  for k in range(4):\n","    print(nn.predict(x_test[k].reshape(-1, 1),y_test[k]))\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"vMqNNPopYjPI","nbgrader":{"checksum":"4ff21be5bf4c5c721cbdbb0d612a9e0c","grade":true,"grade_id":"cell-08caa0ed7b0ce465","locked":true,"points":2,"schema_version":1,"solution":false},"colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"542cc879-cb42-4dbc-a947-d86e7a3552fb","executionInfo":{"status":"ok","timestamp":1560046037694,"user_tz":-330,"elapsed":1111,"user":{"displayName":"Tanuj Singhal","photoUrl":"","userId":"15993466899445923096"}}},"source":["'''Testing the prediction'''\n","x = np.array([0.9,0.9,0.9]).reshape(-1, 1)\n","y = np.array([[0.1],])\n","\n","assert np.all(np.isclose(nn1.predict(x,y),0, atol=0.01))\n","print('Test passed', '\\U0001F44D')"],"execution_count":155,"outputs":[{"output_type":"stream","text":["(3, 1)\n","Test passed üëç\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9-0oU2fCdhRN"},"source":["# Advanced\n","## Does the performance increase with increasing the number of neurons in the hidden layer?\n","- Repeat the training with 1 neuron in the hidden layer, then with 3 neuron and then with 5 neuron in the hidden layer to see the trend in performance\n","- Compare the training error\n","- Compare the testing error"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SNHBGSLBD_t2","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}