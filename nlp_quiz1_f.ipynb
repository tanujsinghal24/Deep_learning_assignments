{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2CO2PQUGYPZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQok29kD8Ofk"
   },
   "source": [
    "\n",
    "\n",
    "## Basic Text Processing\n",
    "### Loading dataset\n",
    "You need not mess with this code. Just run these cells to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "x-jb3k178NcU",
    "outputId": "8e23438e-60a8-4e83-b2b8-c4da1e84fe29"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/krishnamrith12/NotebooksNLP/master/Data/Tokenization/Chat1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "E_k4syLp2JjV",
    "outputId": "4a4528b1-c137-434c-88c9-c5d93e75aa69"
   },
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "print('***********************************************************')\n",
    "print('Your data successfully loaded.')\n",
    "print('First 10 lines of conversation is shown:')\n",
    "print('This is conversation between machine and user.')\n",
    "print('***********************************************************')\n",
    "with open(\"./Chat1.txt\") as myfile:\n",
    "  for x in range(0,10):\n",
    "    print(next(myfile))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rln6iThhdYiD"
   },
   "source": [
    "### Tokenize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qGq1SDMx8e8F"
   },
   "source": [
    "\n",
    "Suppose you are doing operations on string data named '*str = I love CODING.*'\n",
    "\n",
    "1.   Tokenize the data. For eg, output after this step will be ['I', 'love', 'CODING.']\n",
    "2.   Lowercase the data . For ex, your output will be ['i' ,'love', 'coding.']\n",
    "3. Remove the puctuations from data using . For eg, you will get output as ['i' ,'love', 'coding'] (Full stop is removed here). We have provided list of puctuations. So make sure that you remove all the punctuations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1n3YDdWP2V__"
   },
   "outputs": [],
   "source": [
    "f = open('./Chat1.txt','r')\n",
    "content=f.read()\n",
    "\n",
    "# Punctuation list is as follows:\n",
    "punc_list =['.',',',':','!','?','(',')',';']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "1hOjFeKATxo6",
    "nbgrader": {
     "checksum": "330c0d3d591e8b84595cb92f4dd0a2e9",
     "grade": false,
     "grade_id": "cell-879e4be9f192b139",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(raw_data):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    raw_data: string, raw text of the corpus\n",
    "  Outputs:\n",
    "    tokenized_data: list of strings, split raw_data on whitespace  \n",
    "  \"\"\"\n",
    "  # YOUR CODE HERE\n",
    "  return tokenized_data  \n",
    "\n",
    "tokenized_data = tokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "Wk-CNu-fUAFU",
    "nbgrader": {
     "checksum": "eae1f181b6d5e3698830e8a4d7f93131",
     "grade": true,
     "grade_id": "cell-7cf205456c5a3251",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "3ef70837-ce2d-40bb-ce71-f2f5431e7271"
   },
   "outputs": [],
   "source": [
    "\"\"\"Test tokenize\"\"\"\n",
    "def test_tokenize():\n",
    "  assert(tokenized_data[0:5] == ['User:', 'So', \"how's\", 'it', 'going?'])\n",
    "  assert(len(tokenized_data) == 1013)\n",
    "  print('Test passed', '\\U0001F44D')\n",
    "test_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "5UYCl331fR8s",
    "nbgrader": {
     "checksum": "02dac91d63cedd5046f97a226c9fa412",
     "grade": false,
     "grade_id": "cell-d2161471bc313ce0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def lowercase_data(word):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    word: a string\n",
    "  Outputs:\n",
    "    word_lowercase: a string (all alphabets in lowercase)\n",
    "  \"\"\"\n",
    "  # YOUR CODE HERE\n",
    "  return word_lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "50GXtr7YU6cI",
    "nbgrader": {
     "checksum": "57ae44fb96fbf2e3c642fe80a6753d7d",
     "grade": true,
     "grade_id": "cell-7cfca3bf3dcd93d1",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "27446623-28b6-41eb-dd8c-a0b81349c305"
   },
   "outputs": [],
   "source": [
    "\"\"\"Test lowercase_data\"\"\"\n",
    "def test_lowercase_data():\n",
    "  assert(lowercase_data('Machine LEArning is AWesome;') == 'machine learning is awesome;')\n",
    "  print('Test passed', '\\U0001F44D')\n",
    "test_lowercase_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "tY4JnlMQfmXR",
    "nbgrader": {
     "checksum": "476523fa117d71e57a9616665f1f9a59",
     "grade": false,
     "grade_id": "cell-26309439d79eec9d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(word, punc_list):\n",
    "  '''\n",
    "  Inputs:\n",
    "    punc_list: a list (containing punctuation characters)\n",
    "    word: a string\n",
    "  Outputs:\n",
    "    word_no_punc: a string (without any punctuation characters)\n",
    "  '''\n",
    "  # YOUR CODE HERE\n",
    "  return word_no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "oToxFcnBXDk8",
    "nbgrader": {
     "checksum": "aba1c7cd6a3043669d577c12e1906706",
     "grade": true,
     "grade_id": "cell-c7c5ac2cfff31a2e",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "7ab0e7ff-be45-491d-95d5-2cf547815795"
   },
   "outputs": [],
   "source": [
    "\"\"\"Test remove_punctuation\"\"\"\n",
    "def test_remove_punctuation():\n",
    "  assert(remove_punctuation('mac.hin;e le,ar.ning is? awe!some;', punc_list) == 'machine learning is awesome')\n",
    "  assert(remove_punctuation(tokenized_data[4], punc_list) == 'going')\n",
    "  print('Test passed', '\\U0001F44D')\n",
    "test_remove_punctuation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "HK0BX7xD_h-w",
    "nbgrader": {
     "checksum": "cc663cbfeb52549f70b56db1b09885a1",
     "grade": false,
     "grade_id": "cell-656370f38a73238c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(content):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    content: a string\n",
    "  Outputs:\n",
    "    wordlist: a list of strings\n",
    "    \n",
    "  Action:\n",
    "    1. Preprocess the string 'content' using the functions created above (tokenize, lowercase and remove_punctuation) \n",
    "    2. Store it in a list 'wordlist'\n",
    "    \n",
    "  \"\"\"\n",
    "  # YOUR CODE HERE\n",
    "  return wordlist\n",
    "\n",
    "wordlist = preprocess(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "GA5JqHReYdmz",
    "nbgrader": {
     "checksum": "a97eef6fd30ae408844686f3675579ba",
     "grade": true,
     "grade_id": "cell-7ac5de7d7e634c5e",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "6c4c3339-99a6-4a71-9085-64f543c84d8a"
   },
   "outputs": [],
   "source": [
    "\"\"\"Test preprocess\"\"\"\n",
    "def test_preprocess():\n",
    "  assert(len(wordlist) == 1013)\n",
    "  print('Test passed', '\\U0001F44D')\n",
    "test_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FoXZvZUMAG48"
   },
   "source": [
    "### Plot the frequency of words\n",
    "You need to plot the frequncy of words using function provided. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ol_OktB51vH-"
   },
   "outputs": [],
   "source": [
    "def plot_frequency(y):\n",
    "  N = len(y)\n",
    "  x = range(N)\n",
    "  width = 1/0.5\n",
    "  plt.bar(x, y, width, color=\"blue\")\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_9z_wNzFvMh"
   },
   "source": [
    "### To do\n",
    "1) Find out count of each word using  function and store this  in list named word_count using <br>\n",
    "2) Pass the word_count list to function to plot the frequency plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "deletable": false,
    "id": "Bjb8Iyz-5Kn7",
    "nbgrader": {
     "checksum": "ddee3291bc0ca973030fd0233578eac4",
     "grade": false,
     "grade_id": "cell-74a2a6d1b947fd18",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "4b4cabf5-005a-482e-cdae-e6a2a5ee0d08"
   },
   "outputs": [],
   "source": [
    "def frequency(wordlist):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    wordlist: a list of string\n",
    "  Outputs:\n",
    "    word_count: a list, frequency of all the items in wordlist\n",
    "  \"\"\"\n",
    "  # YOUR CODE HERE\n",
    "  return word_count\n",
    "\n",
    "word_count = frequency(wordlist)\n",
    "plot_frequency(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "qyFnPxhJaPw8",
    "nbgrader": {
     "checksum": "e64540120298824fc42229b39835af80",
     "grade": true,
     "grade_id": "cell-a5201c484d0a6d62",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "a76e2bcb-cd14-4337-b228-fc0a5d3370b2"
   },
   "outputs": [],
   "source": [
    "\"\"\"Test frequency\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HaiGyFdMgQnj"
   },
   "source": [
    "## (1) Cosine Similarity\n",
    "When we have word vectors, we need a way to quantify the similarity between individual words, according to these vectors. One such metric is cosine-similarity. We will be using this to find words that are \"close\" and \"far\" from one another.\n",
    "\n",
    "We can think of n-dimensional vectors as points in n-dimensional space. If we take this perspective, *L1* and *L2* Distances help quantify the amount of space \"*we must travel\"* to get between these two points. \n",
    "\n",
    "Another approach is to examine the angle between two vectors. Instead of computing the actual angle, we can leave the similarity in terms of  similarity=cos(Θ) . Formally, the Cosine Similarity  s  between two vectors  p  and  q  is defined as:\n",
    "\n",
    "$s = \\frac{p⋅q}{||p||||q||} $, where s∈[−1,1]<br>\n",
    "You need to implement this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "-SfyCjuDgWR6",
    "nbgrader": {
     "checksum": "bc524554866224301d947cb4069a7b4f",
     "grade": false,
     "grade_id": "cell-0c747a3b2f96a69e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def cosine_similarity(v1,v2):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        v1: list of floats,\n",
    "        v2: list of floats, same length as v1\n",
    "        \n",
    "    Output:\n",
    "        cs: single floating point value, cosine similarity of v1 and v2 as defined above\n",
    "        /\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "ub6xDoSWgaqS",
    "nbgrader": {
     "checksum": "6ed71d817b1bec615bbfd8e2b9320d46",
     "grade": true,
     "grade_id": "cell-a7a84c46a5167540",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "2287e126-5c8f-4c0c-cecf-4be4acc3e58f"
   },
   "outputs": [],
   "source": [
    "'''test for cosine_similarity'''\n",
    "v1,v2 = [3, 45, 7, 2], [2, 5.4, 13, 15]\n",
    "v = cosine_similarity(v1,v2)\n",
    "assert np.isclose(v, 0.39187288174224344, 0.0001)\n",
    "\n",
    "print('Test passed', '\\U0001F44D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCU5rscXGUxK"
   },
   "source": [
    "### Most similar word\n",
    "Implement the function, given a word \"*x*\", it will return most similar word from first column of data, based on similarity measure. <br>\n",
    "For example, for most similar word to *king* could be *man*. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "KAaZGulSJjBm",
    "nbgrader": {
     "checksum": "3760c5dce4bac64c7a369970b9f14055",
     "grade": false,
     "grade_id": "cell-7882664ff09b1996",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def most_similar(input_word,wordvec_dict):\n",
    "  \"\"\"\n",
    "  Input:\n",
    "      input_word: any word\n",
    "      wordvec_dict: dictionary of word vectors(list of floats), where a word is the key and its word_vector is the value\n",
    "      \n",
    "  Output:\n",
    "      out: string, the word in wordvec_dict most similar to 'word'\n",
    "  \"\"\"\n",
    "  # YOUR CODE HERE\n",
    "  return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "vxytbub2Jooo",
    "nbgrader": {
     "checksum": "835796e8ec0c7300555b3efcc638aa59",
     "grade": true,
     "grade_id": "cell-00e66f0dda9fcd70",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "06868383-71d4-416e-9b50-73d0f28ad9da"
   },
   "outputs": [],
   "source": [
    "\n",
    "word_vec_dict = {\n",
    "    'princess': [-1.720603,\t-3.560657],\n",
    "    'queen': [-0.722603,\t-1.232549],\n",
    "    'man':\t[-0.370373,\t0.576843],\n",
    "    'boy':\t[-1.693504,\t0.719822]\n",
    "\n",
    "}\n",
    "\n",
    "'''test for most_similar'''\n",
    "assert most_similar('queen', word_vec_dict) == 'princess'\n",
    "print('Test passed', '\\U0001F44D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WqeQHiW-K45r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_DAY_1_QUIZ_f.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
